{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a541477-8c08-4bd6-a157-c83290c129d3",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "\n",
    "To run the code below correctly follow these instructions:\n",
    "\n",
    "1) Download all of the SNLI dataset from the following link and save just the snli_1.0_train.jsonl and the snli_1.0_test.jsonl version: https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n",
    "2) Download the GloVe model version from: https://nlp.stanford.edu/data/glove.6B.zip and use the glove.6B.50d.txt version\n",
    "3) Unzip/Extract the files if necessary.\n",
    "4) Save those files to the same file area/location to this Notebook.\n",
    "5) Ensure all of the relevent libraries/packages are installed and with the same version number shown below to replicate the results.\n",
    "6) Ensure any log files are deleted before running the code as this will confuse Tensorboard of which files to run if not completed.\n",
    "8) Restart the Keneral and select run all cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209e3582-92c9-46e1-9cff-87e5962ae0af",
   "metadata": {},
   "source": [
    "This model takes around 112 minutes to complete training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8ce76-ba05-450d-83d0-40cd66cb6399",
   "metadata": {},
   "source": [
    "# Step 1 - Import libraries/packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a3a0c4-666f-43fd-b3dd-1b7a24ce6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python version using - 3.12.5\n",
    "import random\n",
    "random.seed(1)\n",
    "import numpy as np # Version - 1.23.4\n",
    "import pandas as pd # Version 2.2.2\n",
    "import os # Version 10.0.22631\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Stops long messages coming through\n",
    "from sklearn import preprocessing # Version 1.5.1\n",
    "import keras # Version 2.6.0\n",
    "import tensorflow as tf # Version 2.6.0\n",
    "from tensorflow.keras.models import Sequential # Version 2.6.0\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D  # Version 2.6.0\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # Version 2.6.0\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences # Version 2.6.0\n",
    "from tensorflow.keras.optimizers import Adam # Version 2.6.0\n",
    "from tensorflow.keras.callbacks import TensorBoard # Version 2.6.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf24526-bc5c-4716-b649-6cb281720743",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a933622-52e1-4001-aa9d-01cc84bf6d39",
   "metadata": {},
   "source": [
    "# Step 2 - Load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf248b07-d1a2-4c81-9828-0bd94965b197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotator_labels</th>\n",
       "      <th>captionID</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>pairID</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence1_binary_parse</th>\n",
       "      <th>sentence1_parse</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>sentence2_binary_parse</th>\n",
       "      <th>sentence2_parse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560147</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>4378810163.jpg#4</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>4378810163.jpg#4r1c</td>\n",
       "      <td>Two women are observing something together.</td>\n",
       "      <td>( ( Two women ) ( ( are ( ( observing somethin...</td>\n",
       "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
       "      <td>Two women are standing with their eyes closed.</td>\n",
       "      <td>( ( ( Two women ) ( are ( standing ( with ( th...</td>\n",
       "      <td>(ROOT (S (NP (NP (CD Two) (NNS women)) (SBAR (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560148</th>\n",
       "      <td>[entailment, entailment, entailment, contradic...</td>\n",
       "      <td>4378810163.jpg#4</td>\n",
       "      <td>entailment</td>\n",
       "      <td>4378810163.jpg#4r1e</td>\n",
       "      <td>Two women are observing something together.</td>\n",
       "      <td>( ( Two women ) ( ( are ( ( observing somethin...</td>\n",
       "      <td>(ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...</td>\n",
       "      <td>Two girls are looking at something.</td>\n",
       "      <td>( ( Two girls ) ( ( are ( looking ( at somethi...</td>\n",
       "      <td>(ROOT (S (NP (CD Two) (NNS girls)) (VP (VBP ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560149</th>\n",
       "      <td>[contradiction, contradiction, contradiction, ...</td>\n",
       "      <td>152881593.jpg#1</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>152881593.jpg#1r1c</td>\n",
       "      <td>A man in a black leather jacket and a book in ...</td>\n",
       "      <td>( ( ( ( ( A man ) ( in ( a ( black ( leather j...</td>\n",
       "      <td>(ROOT (S (NP (NP (NP (DT A) (NN man)) (PP (IN ...</td>\n",
       "      <td>A man is flying a kite.</td>\n",
       "      <td>( ( A man ) ( ( is ( flying ( a kite ) ) ) . ) )</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560150</th>\n",
       "      <td>[entailment, entailment, entailment, neutral, ...</td>\n",
       "      <td>152881593.jpg#1</td>\n",
       "      <td>entailment</td>\n",
       "      <td>152881593.jpg#1r1e</td>\n",
       "      <td>A man in a black leather jacket and a book in ...</td>\n",
       "      <td>( ( ( ( ( A man ) ( in ( a ( black ( leather j...</td>\n",
       "      <td>(ROOT (S (NP (NP (NP (DT A) (NN man)) (PP (IN ...</td>\n",
       "      <td>A man is speaking in a classroom.</td>\n",
       "      <td>( ( A man ) ( ( is ( speaking ( in ( a classro...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560151</th>\n",
       "      <td>[neutral, neutral, neutral, neutral, neutral]</td>\n",
       "      <td>152881593.jpg#1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>152881593.jpg#1r1n</td>\n",
       "      <td>A man in a black leather jacket and a book in ...</td>\n",
       "      <td>( ( ( ( ( A man ) ( in ( a ( black ( leather j...</td>\n",
       "      <td>(ROOT (S (NP (NP (NP (DT A) (NN man)) (PP (IN ...</td>\n",
       "      <td>A man is teaching science in a classroom.</td>\n",
       "      <td>( ( A man ) ( ( is ( ( teaching science ) ( in...</td>\n",
       "      <td>(ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         annotator_labels         captionID  \\\n",
       "560147  [contradiction, contradiction, contradiction, ...  4378810163.jpg#4   \n",
       "560148  [entailment, entailment, entailment, contradic...  4378810163.jpg#4   \n",
       "560149  [contradiction, contradiction, contradiction, ...   152881593.jpg#1   \n",
       "560150  [entailment, entailment, entailment, neutral, ...   152881593.jpg#1   \n",
       "560151      [neutral, neutral, neutral, neutral, neutral]   152881593.jpg#1   \n",
       "\n",
       "           gold_label               pairID  \\\n",
       "560147  contradiction  4378810163.jpg#4r1c   \n",
       "560148     entailment  4378810163.jpg#4r1e   \n",
       "560149  contradiction   152881593.jpg#1r1c   \n",
       "560150     entailment   152881593.jpg#1r1e   \n",
       "560151        neutral   152881593.jpg#1r1n   \n",
       "\n",
       "                                                sentence1  \\\n",
       "560147        Two women are observing something together.   \n",
       "560148        Two women are observing something together.   \n",
       "560149  A man in a black leather jacket and a book in ...   \n",
       "560150  A man in a black leather jacket and a book in ...   \n",
       "560151  A man in a black leather jacket and a book in ...   \n",
       "\n",
       "                                   sentence1_binary_parse  \\\n",
       "560147  ( ( Two women ) ( ( are ( ( observing somethin...   \n",
       "560148  ( ( Two women ) ( ( are ( ( observing somethin...   \n",
       "560149  ( ( ( ( ( A man ) ( in ( a ( black ( leather j...   \n",
       "560150  ( ( ( ( ( A man ) ( in ( a ( black ( leather j...   \n",
       "560151  ( ( ( ( ( A man ) ( in ( a ( black ( leather j...   \n",
       "\n",
       "                                          sentence1_parse  \\\n",
       "560147  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...   \n",
       "560148  (ROOT (S (NP (CD Two) (NNS women)) (VP (VBP ar...   \n",
       "560149  (ROOT (S (NP (NP (NP (DT A) (NN man)) (PP (IN ...   \n",
       "560150  (ROOT (S (NP (NP (NP (DT A) (NN man)) (PP (IN ...   \n",
       "560151  (ROOT (S (NP (NP (NP (DT A) (NN man)) (PP (IN ...   \n",
       "\n",
       "                                             sentence2  \\\n",
       "560147  Two women are standing with their eyes closed.   \n",
       "560148             Two girls are looking at something.   \n",
       "560149                         A man is flying a kite.   \n",
       "560150               A man is speaking in a classroom.   \n",
       "560151       A man is teaching science in a classroom.   \n",
       "\n",
       "                                   sentence2_binary_parse  \\\n",
       "560147  ( ( ( Two women ) ( are ( standing ( with ( th...   \n",
       "560148  ( ( Two girls ) ( ( are ( looking ( at somethi...   \n",
       "560149   ( ( A man ) ( ( is ( flying ( a kite ) ) ) . ) )   \n",
       "560150  ( ( A man ) ( ( is ( speaking ( in ( a classro...   \n",
       "560151  ( ( A man ) ( ( is ( ( teaching science ) ( in...   \n",
       "\n",
       "                                          sentence2_parse  \n",
       "560147  (ROOT (S (NP (NP (CD Two) (NNS women)) (SBAR (...  \n",
       "560148  (ROOT (S (NP (CD Two) (NNS girls)) (VP (VBP ar...  \n",
       "560149  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...  \n",
       "560150  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...  \n",
       "560151  (ROOT (S (NP (DT A) (NN man)) (VP (VBZ is) (VP...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_snli = pd.read_json(\"snli_1.0_train.jsonl\", lines=True) # Reads the train_snli file, this is the dataset used for training\n",
    "test_snli = pd.read_json(\"snli_1.0_test.jsonl\", lines = True) # Reads the test_snli file, this is the dataset used for testing\n",
    "\n",
    "full_dataset = [train_snli,test_snli] # Concatenates the data, to make one data frame\n",
    "\n",
    "full_dataset = pd.concat(full_dataset, ignore_index=True) # concatenates the train and test dataset together\n",
    "\n",
    "full_dataset.tail() # Checks if the dataset has been concatenated correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbb057-f0e2-48dc-89d0-5dfb215d02f9",
   "metadata": {},
   "source": [
    "# Step - 3 Exploaratory data analysis and Pre-processing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6de229-4e91-498f-aec3-986f9d428c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280076\n"
     ]
    }
   ],
   "source": [
    "FiftyPercentFullDataset = round((50 * len(full_dataset) / 100)) # Finds half (50%) of the total number of rows, to split the dataset in half, round is there to get to the nearest integer\n",
    "\n",
    "FiftyPercentFullDataset = full_dataset.iloc[0:FiftyPercentFullDataset] # Uses Python slicing to with the variable shown above to cut the dataset in half\n",
    "\n",
    "print(len(FiftyPercentFullDataset)) # Checks the length of the dataset to see if it has been cut in half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6a743f3-03e1-490c-a8d5-9d040f6319a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "FiftyPercentFullDataset = FiftyPercentFullDataset[['sentence1', 'sentence2','gold_label']] # Selects only the Premise (sentence1), the Hypothesis (sentence2), and the Label (gold_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbc4d6df-c6a8-4c07-9f17-e25c4eca40b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence1     object\n",
       "sentence2     object\n",
       "gold_label    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FiftyPercentFullDataset.dtypes # Looks at the data types of each covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d1d8199-e278-48af-aa49-57a14e165d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence1  sentence2  gold_label\n",
       "False      False      False         280076\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA_train = FiftyPercentFullDataset.isnull() \n",
    "\n",
    "NA_train.value_counts() # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eb73f83-bdfa-4555-9664-bcc1ffe5255b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "entailment       93428\n",
       "contradiction    93265\n",
       "neutral          93029\n",
       "-                  354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FiftyPercentFullDataset['gold_label'].value_counts() # Looks at the counts of all possible values in the gold_label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24a61574-b3f4-4f14-b1b6-ad57bac739f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gold_label\n",
       "entailment       93428\n",
       "contradiction    93265\n",
       "neutral          93029\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removes the \"-\" label in the dataset, since if it is used it will lead to inaccurate results\n",
    "\n",
    "FiftyPercentFullDataset = FiftyPercentFullDataset[FiftyPercentFullDataset['gold_label'] != \"-\"]\n",
    "FiftyPercentFullDataset.tail()\n",
    "FiftyPercentFullDataset['gold_label'].value_counts() # Checks if the '-' label has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d9c696-de46-4ea0-ac31-17be1231854d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renames columns to enable easier readings of the covariates\n",
    "\n",
    "FiftyPercentFullDataset = FiftyPercentFullDataset.rename(columns = {\"sentence1\": \"Premise\", \"sentence2\": \"Hypothesis\", \"gold_label\": \"Label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3483fbb1-26cc-4bef-8573-8858daf5ff02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Premise</th>\n",
       "      <th>Hypothesis</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>280071</th>\n",
       "      <td>An ATV rider, speeds around a corner, while sl...</td>\n",
       "      <td>A man rides an ATV down a dirt path.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280072</th>\n",
       "      <td>An ATV rider, speeds around a corner, while sl...</td>\n",
       "      <td>A ATV rider just fell of their ATV into a river.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280073</th>\n",
       "      <td>An ATV rider, speeds around a corner, while sl...</td>\n",
       "      <td>An ATV rider is in the woods.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280074</th>\n",
       "      <td>An ATV rider, speeds around a corner, while sl...</td>\n",
       "      <td>A person rides an ATV while focusing on the tr...</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280075</th>\n",
       "      <td>An ATV rider, speeds around a corner, while sl...</td>\n",
       "      <td>A man rides a motorcycle down a dirt trail, ar...</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Premise  \\\n",
       "280071  An ATV rider, speeds around a corner, while sl...   \n",
       "280072  An ATV rider, speeds around a corner, while sl...   \n",
       "280073  An ATV rider, speeds around a corner, while sl...   \n",
       "280074  An ATV rider, speeds around a corner, while sl...   \n",
       "280075  An ATV rider, speeds around a corner, while sl...   \n",
       "\n",
       "                                               Hypothesis          Label  \n",
       "280071               A man rides an ATV down a dirt path.        neutral  \n",
       "280072   A ATV rider just fell of their ATV into a river.  contradiction  \n",
       "280073                      An ATV rider is in the woods.        neutral  \n",
       "280074  A person rides an ATV while focusing on the tr...     entailment  \n",
       "280075  A man rides a motorcycle down a dirt trail, ar...  contradiction  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FiftyPercentFullDataset.tail() # Checks if the covariates have been renamed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac272ed-d5cf-4ceb-9512-15a68dabd39d",
   "metadata": {},
   "source": [
    "# Step 4 - Create Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac73bb94-69d4-4a20-a133-280181e43821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "covariatePremise = FiftyPercentFullDataset['Premise']\n",
    "covariateHypothesis = FiftyPercentFullDataset['Hypothesis']\n",
    "\n",
    "\n",
    "labels = FiftyPercentFullDataset['Label'] # Makes the label covaraite into its own data frame\n",
    "\n",
    "\n",
    "LabelEncoder = preprocessing.LabelEncoder()\n",
    "labels = LabelEncoder.fit_transform(labels)\n",
    "\n",
    "labels = tf.keras.utils.to_categorical(labels, 3).astype(\"int32\") # Assigns the labels as ints.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6f89b55-bef8-43e9-b465-1cbc102297e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(279722, 50)\n",
      "(279722, 50)\n"
     ]
    }
   ],
   "source": [
    "premiseTokeniser = Tokenizer(num_words = 300) # Applies a maximum of 300 words for the Premise\n",
    "hypothesisTokeniser = Tokenizer(num_words = 300) # Applies a maximum of 300 words for the Hypothesis\n",
    "\n",
    "premiseTokeniser.fit_on_texts(covariatePremise)\n",
    "hypothesisTokeniser.fit_on_texts(covariateHypothesis)\n",
    "\n",
    "#Below converts all the sentences to their own token-ID sequences. This is necessary for LSTMs since they work on sequences \n",
    "premiseSequences = premiseTokeniser.texts_to_sequences(covariatePremise)\n",
    "hypothesisSequences = hypothesisTokeniser.texts_to_sequences(covariateHypothesis)\n",
    "\n",
    "premisePadded = pad_sequences(premiseSequences, maxlen=50) # Makes all sequences to a fixed length of 50, this is the first input of the model\n",
    "hypothesisPadded = pad_sequences(hypothesisSequences, maxlen=50) # This is the second input of the model\n",
    "\n",
    "print(premisePadded.shape) # Checks if the padding has worked\n",
    "print(hypothesisPadded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b397afbc-2996-4685-8d36-5f5c02f410fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279722\n",
      "223778\n",
      "55944\n",
      "279722\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The code below splits the dataset.\n",
    "'''\n",
    "\n",
    "\n",
    "TestSplit = 0.2 # Used for the testing set\n",
    "\n",
    "TestSplit = int(TestSplit * len(premisePadded)) # Finds 20% of the dataset for the testing split.\n",
    "\n",
    "\n",
    "# Below does Python slicing to only get 80% of the data by using the - operation\n",
    "premisePaddedTrain = premisePadded[:-TestSplit]\n",
    "hypothesisPaddedTrain = hypothesisPadded[:-TestSplit]\n",
    "labelTrain = labels[:-TestSplit]\n",
    "\n",
    "# Below does Python slicing to only get 20% of the data by using the - operation\n",
    "premisePaddedTest = premisePadded[-TestSplit:]\n",
    "hypothesisPaddedTest = hypothesisPadded[-TestSplit:]\n",
    "labelTest = labels[-TestSplit:]\n",
    "\n",
    "print(len(FiftyPercentFullDataset))\n",
    "print(len(premisePaddedTrain)) # Checks the size of them to ensure that the splitting has worked\n",
    "print(len(premisePaddedTest))\n",
    "\n",
    "print(len(premisePaddedTrain) + len(premisePaddedTest)) # Checks if the lengths of the splitting are the same size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10fa8271-9135-40a9-874c-e7d5c1519a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenDictionary = {} # A dictionary to store each word\n",
    "\n",
    "with open(file = \"glove.6B.50d.txt\", encoding=\"utf8\") as glove: # This glove file is the smallest possiblee glove file, it has 6 billion words with 50 dimensions\n",
    "\n",
    "    for entry in glove:\n",
    "        \n",
    "        entryLine = entry.split()\n",
    "        entryVector = np.array(entryLine[1:]) # First character is always the word, hence we start with the second character to get the numerical values\n",
    "        entryVector = entryVector.astype(np.float32) # Since the numbers are strings at first, change them to a number\n",
    "\n",
    "        if entryVector.shape[0] == 50:\n",
    "            tokenDictionary[entryLine[0]] = entryVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09d04880-a34e-448d-9906-632d8bbe6676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14336, 50)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Below creates an embedding matrix for the Premise covariate\n",
    "'''\n",
    "\n",
    "premiseEmbeddingMatrix = np.zeros((len(premiseTokeniser.word_index) + 1, 50)) # A numpy array full of zeros is made, to handle Out-of-Vocabulary\n",
    "\n",
    "for character, i in premiseTokeniser.word_index.items(): # Character can either be a punctuation or a word \n",
    "    premiseEmbVector = tokenDictionary.get(character)\n",
    "    if premiseEmbVector is not None:\n",
    "        premiseEmbeddingMatrix[i] = premiseEmbVector\n",
    "\n",
    "\n",
    "print(premiseEmbeddingMatrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6faeb88e-d445-44ed-b682-ccd27fc3778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23202, 50)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Below creates an embedding matrix for the Premise covariate\n",
    "'''\n",
    "\n",
    "hypothesisEmbeddingMatrix = np.zeros((len(hypothesisTokeniser.word_index) + 1, 50))\n",
    "\n",
    "\n",
    "for character, i in hypothesisTokeniser.word_index.items():\n",
    "    hypothesisEmbVector = tokenDictionary.get(character)\n",
    "    if hypothesisEmbVector is not None:\n",
    "        hypothesisEmbeddingMatrix[i] = hypothesisEmbVector\n",
    "\n",
    "\n",
    "print(hypothesisEmbeddingMatrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f18f42-b33f-4b26-a15c-6e33e7391682",
   "metadata": {},
   "source": [
    "# Step 5 - Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfe730ad-7dcc-4910-aa58-662d0a793a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "premiseEmbeddingLayer = keras.layers.Embedding( # Creates the embedding layer for the Premise Covariate\n",
    "    14336,\n",
    "    50,\n",
    "    trainable = False, # These should not update during training\n",
    ")\n",
    "\n",
    "premiseEmbeddingLayer.build((1,))\n",
    "premiseEmbeddingLayer.set_weights([premiseEmbeddingMatrix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf4ce44a-7936-48e5-987d-a15e66fe8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesisembeddinglayer = keras.layers.Embedding( # Creates the embedding layer for the Hypothesis Covariate\n",
    "    23202,\n",
    "    50,\n",
    "    trainable = False, # These should not update during training - since they are the pre-trained embeddings.\n",
    ")\n",
    "\n",
    "hypothesisembeddinglayer.build((1,))\n",
    "hypothesisembeddinglayer.set_weights([hypothesisEmbeddingMatrix])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4fc43e8-a92f-4583-839e-62361612fbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer BiLSTMLayer1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer BiLSTMLayer3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Premise (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Hypothesis (InputLayer)         [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 50)       716800      Premise[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 50)       1160100     Hypothesis[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 50, 100)      0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 50, 128)      84480       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 50, 128)      0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 50, 128)      98816       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 50, 128)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 50, 128)      98816       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 50, 128)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "final_output (Dense)            (None, 3)            771         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,159,783\n",
      "Trainable params: 282,883\n",
      "Non-trainable params: 1,876,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_Bi_LSTM = Sequential() # Creates a Sequential Keras model\n",
    "\n",
    "input1 = keras.Input(shape=(50,), dtype=\"float\", name =\"Premise\")\n",
    "input2 = keras.Input(shape=(50,), dtype=\"float\", name =\"Hypothesis\")\n",
    "\n",
    "embeddedSequencesPremise = premiseEmbeddingLayer(input1)\n",
    "embeddedSequencesHypothesis = hypothesisembeddinglayer(input2)\n",
    "\n",
    "x = keras.layers.concatenate([embeddedSequencesPremise, embeddedSequencesHypothesis]) # Concatenates the embedding layers into one embedding layer.\n",
    "\n",
    "x = keras.layers.Bidirectional(LSTM(64, return_sequences = True, recurrent_dropout = 0.2, name= \"BiLSTMLayer1\"))(x)\n",
    "x = keras.layers.Dropout(0.25)(x) # Adds drop out layers to prevent overfitting\n",
    "x = keras.layers.Bidirectional(LSTM(64, return_sequences = True, recurrent_dropout = 0.2, name= \"BiLSTMLayer2\"))(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "x = keras.layers.Bidirectional(LSTM(64, return_sequences = True, recurrent_dropout = 0.2, name= \"BiLSTMLayer3\"))(x)\n",
    "x = keras.layers.Dropout(0.25)(x)\n",
    "\n",
    "averagePooling = keras.layers.GlobalAveragePooling1D()(x)\n",
    "maxPooling =  keras.layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "x = keras.layers.concatenate([averagePooling, maxPooling]) # Concatenates the pooling layers into one layer\n",
    "\n",
    "output = keras.layers.Dense(3, activation = \"softmax\", name = \"final_output\")(x) # Output layer\n",
    "\n",
    "model_Bi_LSTM = keras.Model(inputs=[input1,input2], outputs = output)\n",
    "\n",
    "model_Bi_LSTM.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer = Adam(learning_rate=0.001),\n",
    "              metrics = ['accuracy'],\n",
    "             )\n",
    "\n",
    "model_Bi_LSTM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164beab-bc88-4381-9d3f-e86c222612ae",
   "metadata": {},
   "source": [
    "# Step 6 - Train and Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03afddaf-3b56-4a68-a522-00aca2cf48f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoard( # Creates a logger for Tensorboard so it can show the results of the model during training.\n",
    "    log_dir = \"logs_BiLSTM\",\n",
    "    histogram_freq=1, # This will create statistical data of the accuracy, loss etc every epoch.\n",
    "    write_graph = True,\n",
    "    write_images = True\n",
    "    # The two lines above is telling Tensorflow to not only log textual data, but to also create visual representations of the models architecture as well the training process \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44d723c2-e9a1-4c22-a9bd-dfdefe3c7085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "787/787 [==============================] - 695s 870ms/step - loss: 0.9851 - accuracy: 0.5080 - val_loss: 0.9393 - val_accuracy: 0.5500\n",
      "Epoch 2/10\n",
      "787/787 [==============================] - 678s 862ms/step - loss: 0.9110 - accuracy: 0.5691 - val_loss: 0.9016 - val_accuracy: 0.5850\n",
      "Epoch 3/10\n",
      "787/787 [==============================] - 681s 866ms/step - loss: 0.8777 - accuracy: 0.5933 - val_loss: 0.8803 - val_accuracy: 0.6003\n",
      "Epoch 4/10\n",
      "787/787 [==============================] - 673s 856ms/step - loss: 0.8543 - accuracy: 0.6093 - val_loss: 0.8655 - val_accuracy: 0.6113\n",
      "Epoch 5/10\n",
      "787/787 [==============================] - 666s 846ms/step - loss: 0.8317 - accuracy: 0.6232 - val_loss: 0.8351 - val_accuracy: 0.6254\n",
      "Epoch 6/10\n",
      "787/787 [==============================] - 674s 857ms/step - loss: 0.8153 - accuracy: 0.6329 - val_loss: 0.8317 - val_accuracy: 0.6287\n",
      "Epoch 7/10\n",
      "787/787 [==============================] - 677s 860ms/step - loss: 0.8021 - accuracy: 0.6400 - val_loss: 0.8223 - val_accuracy: 0.6320\n",
      "Epoch 8/10\n",
      "787/787 [==============================] - 675s 858ms/step - loss: 0.7907 - accuracy: 0.6453 - val_loss: 0.8176 - val_accuracy: 0.6360\n",
      "Epoch 9/10\n",
      "787/787 [==============================] - 676s 858ms/step - loss: 0.7809 - accuracy: 0.6512 - val_loss: 0.8231 - val_accuracy: 0.6295\n",
      "Epoch 10/10\n",
      "787/787 [==============================] - 674s 857ms/step - loss: 0.7726 - accuracy: 0.6556 - val_loss: 0.8064 - val_accuracy: 0.6401\n",
      "Testing Model: \n",
      "........................\n",
      "1749/1749 [==============================] - 193s 110ms/step - loss: 0.8050 - accuracy: 0.6405\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.804968535900116, 0.6405333876609802]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model_Bi_LSTM.fit([premisePaddedTrain, hypothesisPaddedTrain], labelTrain, # Fits the model, and trains it.\n",
    "                batch_size = 256,\n",
    "                epochs = 10, # The neural network will go around itself 10 times.\n",
    "                verbose = 1,\n",
    "                validation_split = 0.1, # During training it will take 10% of the dataset for validation.\n",
    "                callbacks = [logger])\n",
    "\n",
    "print(\"Testing Model: \\n........................\")\n",
    "\n",
    "model_Bi_LSTM.evaluate([premisePaddedTest, hypothesisPaddedTest], labelTest) # Tests the model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "304147b2-4882-4ffc-9bff-940275ecad74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensorboard --logdir=logs_BiLSTM # Activates Tensorboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e050bc0-a091-4a98-be60-820f779c6292",
   "metadata": {},
   "source": [
    "# End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
